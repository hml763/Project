{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from sklearn.utils.testing import all_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_datas = pd.read_csv('C:/Users/user/Documents/카카오톡 받은 파일/Total_datas.csv')\n",
    "Total_labels =  pd.read_csv('C:/Users/user/Documents/카카오톡 받은 파일/Total_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Total_datas, Total_labels, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allgo = np.arange(100)\n",
    "allgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:645: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB\n",
      "CalibratedClassifierCV\n",
      "CategoricalNB\n",
      "CheckingClassifier\n",
      "테스트 세트 정확도: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "DummyClassifier\n",
      "테스트 세트 정확도: 0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  \"stratified to prior in 0.24.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "테스트 세트 정확도: 0.189\n",
      "GradientBoostingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoostingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis\n",
      "LinearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NearestCentroid\n",
      "NuSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron\n",
      "QuadraticDiscriminantAnalysis\n",
      "테스트 세트 정확도: 0.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:404: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  SupervisedIntegerMixin.fit(self, X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadiusNeighborsClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:940: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:1853: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier\n",
      "RidgeClassifierCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#9:50\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.utils.testing import all_estimators\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "for name, Clf in all_estimators(type_filter='classifier'):\n",
    "warnings.filterwarnings('ignore')\n",
    "    try:\n",
    "        clf = Clf()\n",
    "        warnings.filterwarnings('ignore')\n",
    "        clf.fit(X_train,y_train)\n",
    "        print (name)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(y_test, y_pred)))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier 모델의 테스트 세트 정확도:  0.5624442063917158\n",
      "BaggingClassifier 모델의 테스트 세트 정확도:  0.6756025709694697\n",
      "BernoulliNB 모델의 테스트 세트 정확도:  0.45256204249241205\n",
      "CalibratedClassifierCV 모델의 테스트 세트 정확도:  0.3549455454383146\n",
      "CategoricalNB 모델의 테스트 세트 정확도:  0.37730762363863596\n",
      "CheckingClassifier 모델의 테스트 세트 정확도:  0.15008926977325476\n",
      "DecisionTreeClassifier 모델의 테스트 세트 정확도:  0.6336814854490269\n",
      "DummyClassifier 모델의 테스트 세트 정확도:  0.2762185324049277\n",
      "ExtraTreeClassifier 모델의 테스트 세트 정확도:  0.6279057311194429\n",
      "ExtraTreesClassifier 모델의 테스트 세트 정확도:  0.690242813783253\n",
      "GaussianNB 모델의 테스트 세트 정확도:  0.4430012497768256\n",
      "GradientBoostingClassifier 모델의 테스트 세트 정확도:  0.7099803606498839\n",
      "HistGradientBoostingClassifier 모델의 테스트 세트 정확도:  0.7214693804677736\n",
      "KNeighborsClassifier 모델의 테스트 세트 정확도:  0.6949116229244777\n",
      "LinearDiscriminantAnalysis 모델의 테스트 세트 정확도:  0.357980717728977\n",
      "LinearSVC 모델의 테스트 세트 정확도:  0.35085698982324587\n",
      "LogisticRegression 모델의 테스트 세트 정확도:  0.36247991430101767\n",
      "LogisticRegressionCV 모델의 테스트 세트 정확도:  0.37828066416711303\n",
      "MLPClassifier 모델의 테스트 세트 정확도:  0.714524192108552\n",
      "NearestCentroid 모델의 테스트 세트 정확도:  0.36865738261024816\n"
     ]
    }
   ],
   "source": [
    "#9:50\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.utils.testing import all_estimators\n",
    "import random\n",
    "\n",
    "for name, Clf in all_estimators(type_filter='classifier'):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    try:\n",
    "        clf = Clf()\n",
    "        warnings.filterwarnings('ignore')\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name, \"모델의 테스트 세트 정확도: \", accuracy_score(y_test, y_pred))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier 모델의 테스트 세트 정확도:  0.5686216747009463\n",
      "BaggingClassifier 모델의 테스트 세트 정확도:  0.6755311551508659\n",
      "BernoulliNB 모델의 테스트 세트 정확도:  0.4540885556150687\n",
      "CalibratedClassifierCV 모델의 테스트 세트 정확도:  0.3532672737011248\n",
      "CategoricalNB 모델의 테스트 세트 정확도:  0.37635243706480986\n",
      "CheckingClassifier 모델의 테스트 세트 정확도:  0.15005356186395286\n",
      "DecisionTreeClassifier 모델의 테스트 세트 정확도:  0.633494018925192\n",
      "DummyClassifier 모델의 테스트 세트 정확도:  0.2788073558293162\n",
      "ExtraTreeClassifier 모델의 테스트 세트 정확도:  0.6324227816461346\n",
      "ExtraTreesClassifier 모델의 테스트 세트 정확도:  0.6920282092483485\n",
      "GaussianNB 모델의 테스트 세트 정확도:  0.44042135332976257\n",
      "GradientBoostingClassifier 모델의 테스트 세트 정확도:  0.7100339225138368\n",
      "HistGradientBoostingClassifier 모델의 테스트 세트 정확도:  0.7198268166398857\n",
      "KNeighborsClassifier 모델의 테스트 세트 정확도:  0.692037136225674\n",
      "LinearDiscriminantAnalysis 모델의 테스트 세트 정확도:  0.3563024459917872\n",
      "LinearSVC 모델의 테스트 세트 정확도:  0.34989287627209426\n",
      "LogisticRegression 모델의 테스트 세트 정확도:  0.36035529369755404\n",
      "LogisticRegressionCV 모델의 테스트 세트 정확도:  0.3772808427066595\n",
      "MLPClassifier 모델의 테스트 세트 정확도:  0.7146223888591323\n",
      "NearestCentroid 모델의 테스트 세트 정확도:  0.365532940546331\n",
      "NuSVC 모델의 테스트 세트 정확도:  0.6566505981074808\n",
      "PassiveAggressiveClassifier 모델의 테스트 세트 정확도:  0.3654168898410998\n",
      "Perceptron 모델의 테스트 세트 정확도:  0.26539903588644886\n",
      "QuadraticDiscriminantAnalysis 모델의 테스트 세트 정확도:  0.542465631137297\n",
      "RandomForestClassifier 모델의 테스트 세트 정확도:  0.6949830387430815\n",
      "RidgeClassifier 모델의 테스트 세트 정확도:  0.34857168362792357\n",
      "RidgeClassifierCV 모델의 테스트 세트 정확도:  0.34857168362792357\n",
      "SGDClassifier 모델의 테스트 세트 정확도:  0.32547759328691306\n",
      "SVC 모델의 테스트 세트 정확도:  0.7020174968755579\n"
     ]
    }
   ],
   "source": [
    "#9:50\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.utils.testing import all_estimators\n",
    "import random\n",
    "\n",
    "for name, Clf in all_estimators(type_filter='classifier'):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    try:\n",
    "        clf = Clf()\n",
    "        warnings.filterwarnings('ignore')\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name, \"모델의 테스트 세트 정확도: \", accuracy_score(y_test, y_pred))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warnings.filterwarnings('ignore')\n",
    "allAlgorithms = all_estimators(type_filter=\"classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-98cfa4440c2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallAlgorithms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict_proba'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'base_estimator'"
     ]
    }
   ],
   "source": [
    "for name, algorithm in allAlgorithms:\n",
    "    if hasattr(algorithm, 'predict_proba'):\n",
    "        clf = algorithm()\n",
    "        clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> AdaBoostClassifier\n",
      "<class 'sklearn.ensemble.bagging.BaggingClassifier'> BaggingClassifier\n",
      "<class 'sklearn.naive_bayes.BernoulliNB'> BernoulliNB\n",
      "<class 'sklearn.calibration.CalibratedClassifierCV'> CalibratedClassifierCV\n",
      "<class 'sklearn.multioutput.ClassifierChain'> ClassifierChain\n",
      "<class 'sklearn.naive_bayes.ComplementNB'> ComplementNB\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'> DecisionTreeClassifier\n",
      "<class 'sklearn.dummy.DummyClassifier'> DummyClassifier\n",
      "<class 'sklearn.tree.tree.ExtraTreeClassifier'> ExtraTreeClassifier\n",
      "<class 'sklearn.ensemble.forest.ExtraTreesClassifier'> ExtraTreesClassifier\n",
      "<class 'sklearn.naive_bayes.GaussianNB'> GaussianNB\n",
      "<class 'sklearn.gaussian_process.gpc.GaussianProcessClassifier'> GaussianProcessClassifier\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'> GradientBoostingClassifier\n",
      "<class 'sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier'> HistGradientBoostingClassifier\n",
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'> KNeighborsClassifier\n",
      "<class 'sklearn.semi_supervised.label_propagation.LabelPropagation'> LabelPropagation\n",
      "<class 'sklearn.semi_supervised.label_propagation.LabelSpreading'> LabelSpreading\n",
      "<class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'> LinearDiscriminantAnalysis\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'> LogisticRegression\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegressionCV'> LogisticRegressionCV\n",
      "<class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'> MLPClassifier\n",
      "<class 'sklearn.multioutput.MultiOutputClassifier'> MultiOutputClassifier\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'> MultinomialNB\n",
      "<class 'sklearn.svm.classes.NuSVC'> NuSVC\n",
      "<class 'sklearn.multiclass.OneVsRestClassifier'> OneVsRestClassifier\n",
      "<class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'> QuadraticDiscriminantAnalysis\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'> RandomForestClassifier\n",
      "<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> SGDClassifier\n",
      "<class 'sklearn.svm.classes.SVC'> SVC\n",
      "<class 'sklearn.ensemble.voting.VotingClassifier'> VotingClassifier\n"
     ]
    }
   ],
   "source": [
    "for name, clf in all_estimators(type_filter='classifier'):\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "        print(clf, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "BaggingClassifier\n",
      "BernoulliNB\n",
      "CalibratedClassifierCV\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-01d4d1635380>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mall_estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;34m'sample_weight'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'base_estimator'"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from sklearn.utils.testing import all_estimators\n",
    "for name, clf in all_estimators(type_filter='classifier'):\n",
    "    if 'sample_weight' in inspect.getargspec(clf().fit)[0]:\n",
    "       print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.testing import all_estimators\n",
    "all_est = all_estimators(type_filter=None)\n",
    "all_classifiers = all_estimators(type_filter=\"classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "all_classifiers_fit_args = {}\n",
    "for name, clf in all_classifiers:\n",
    "    all_classifiers_fit_args[name] = inspect.signature(clf.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_classifier</th>\n",
       "      <th>args</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CalibratedClassifierCV</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CheckingClassifier</td>\n",
       "      <td>(self, X, y, **fit_params)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ClassifierChain</td>\n",
       "      <td>(self, X, Y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>(self, X, y, sample_weight=None, check_input=T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>(self, X, y, sample_weight=None, check_input=T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>(self, X, y, sample_weight=None, monitor=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LabelPropagation</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LabelSpreading</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MultiOutputClassifier</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>OneVsOneClassifier</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>OneVsRestClassifier</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>OutputCodeClassifier</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>(self, X, y, coef_init=None, intercept_init=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>(self, X, y, coef_init=None, intercept_init=No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RadiusNeighborsClassifier</td>\n",
       "      <td>(self, X, y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>(self, X, y, coef_init=None, intercept_init=No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SVC</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>(self, X, y, sample_weight=None)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    fit_classifier  \\\n",
       "0               AdaBoostClassifier   \n",
       "1                BaggingClassifier   \n",
       "2                      BernoulliNB   \n",
       "3           CalibratedClassifierCV   \n",
       "4               CheckingClassifier   \n",
       "5                  ClassifierChain   \n",
       "6                     ComplementNB   \n",
       "7           DecisionTreeClassifier   \n",
       "8                  DummyClassifier   \n",
       "9              ExtraTreeClassifier   \n",
       "10            ExtraTreesClassifier   \n",
       "11                      GaussianNB   \n",
       "12       GaussianProcessClassifier   \n",
       "13      GradientBoostingClassifier   \n",
       "14  HistGradientBoostingClassifier   \n",
       "15            KNeighborsClassifier   \n",
       "16                LabelPropagation   \n",
       "17                  LabelSpreading   \n",
       "18      LinearDiscriminantAnalysis   \n",
       "19                       LinearSVC   \n",
       "20              LogisticRegression   \n",
       "21            LogisticRegressionCV   \n",
       "22                   MLPClassifier   \n",
       "23           MultiOutputClassifier   \n",
       "24                   MultinomialNB   \n",
       "25                 NearestCentroid   \n",
       "26                           NuSVC   \n",
       "27              OneVsOneClassifier   \n",
       "28             OneVsRestClassifier   \n",
       "29            OutputCodeClassifier   \n",
       "30     PassiveAggressiveClassifier   \n",
       "31                      Perceptron   \n",
       "32   QuadraticDiscriminantAnalysis   \n",
       "33       RadiusNeighborsClassifier   \n",
       "34          RandomForestClassifier   \n",
       "35                 RidgeClassifier   \n",
       "36               RidgeClassifierCV   \n",
       "37                   SGDClassifier   \n",
       "38                             SVC   \n",
       "39                VotingClassifier   \n",
       "\n",
       "                                                 args  \n",
       "0                    (self, X, y, sample_weight=None)  \n",
       "1                    (self, X, y, sample_weight=None)  \n",
       "2                    (self, X, y, sample_weight=None)  \n",
       "3                    (self, X, y, sample_weight=None)  \n",
       "4                          (self, X, y, **fit_params)  \n",
       "5                                        (self, X, Y)  \n",
       "6                    (self, X, y, sample_weight=None)  \n",
       "7   (self, X, y, sample_weight=None, check_input=T...  \n",
       "8                    (self, X, y, sample_weight=None)  \n",
       "9   (self, X, y, sample_weight=None, check_input=T...  \n",
       "10                   (self, X, y, sample_weight=None)  \n",
       "11                   (self, X, y, sample_weight=None)  \n",
       "12                                       (self, X, y)  \n",
       "13     (self, X, y, sample_weight=None, monitor=None)  \n",
       "14                                       (self, X, y)  \n",
       "15                                       (self, X, y)  \n",
       "16                                       (self, X, y)  \n",
       "17                                       (self, X, y)  \n",
       "18                                       (self, X, y)  \n",
       "19                   (self, X, y, sample_weight=None)  \n",
       "20                   (self, X, y, sample_weight=None)  \n",
       "21                   (self, X, y, sample_weight=None)  \n",
       "22                                       (self, X, y)  \n",
       "23                   (self, X, y, sample_weight=None)  \n",
       "24                   (self, X, y, sample_weight=None)  \n",
       "25                                       (self, X, y)  \n",
       "26                   (self, X, y, sample_weight=None)  \n",
       "27                                       (self, X, y)  \n",
       "28                                       (self, X, y)  \n",
       "29                                       (self, X, y)  \n",
       "30  (self, X, y, coef_init=None, intercept_init=None)  \n",
       "31  (self, X, y, coef_init=None, intercept_init=No...  \n",
       "32                                       (self, X, y)  \n",
       "33                                       (self, X, y)  \n",
       "34                   (self, X, y, sample_weight=None)  \n",
       "35                   (self, X, y, sample_weight=None)  \n",
       "36                   (self, X, y, sample_weight=None)  \n",
       "37  (self, X, y, coef_init=None, intercept_init=No...  \n",
       "38                   (self, X, y, sample_weight=None)  \n",
       "39                   (self, X, y, sample_weight=None)  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(all_classifiers_fit_args.items(), columns=[\"fit_classifier\", \"args\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "BaggingClassifier\n",
      "BernoulliNB\n",
      "CalibratedClassifierCV\n",
      "CheckingClassifier\n",
      "DecisionTreeClassifier\n",
      "DummyClassifier\n",
      "ExtraTreeClassifier\n",
      "ExtraTreesClassifier\n",
      "GaussianNB\n",
      "GradientBoostingClassifier\n",
      "HistGradientBoostingClassifier\n",
      "KNeighborsClassifier\n",
      "LinearDiscriminantAnalysis\n",
      "LinearSVC\n",
      "LogisticRegression\n",
      "LogisticRegressionCV\n",
      "MLPClassifier\n",
      "NearestCentroid\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.utils.testing import all_estimators\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "for name, Clf in all_estimators(type_filter='classifier'):\n",
    "    try:\n",
    "        clf = Clf()\n",
    "        clf.fit(X_train,y_train)\n",
    "        print (name)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(name, \"의 정확도 : \", accuracy_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
